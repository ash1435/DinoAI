{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mss import mss\n",
    "import pydirectinput\n",
    "import cv2 as cv\n",
    "import numpy as np\n",
    "import pytesseract\n",
    "import easyocr\n",
    "import time\n",
    "import matplotlib.pyplot as plt\n",
    "from gym import Env\n",
    "from gym.spaces import Box, Discrete\n",
    "import pickle\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def easyocr_read(file: str, reader):\n",
    "\n",
    "    results = reader.readtext(file)\n",
    "    results = sorted(results, key=lambda x: x[0][0])\n",
    "    text_results = [x[-2] for x in results]\n",
    "    easy_output = \" \".join(text_results)  \n",
    "    easy_output = easy_output.strip() \n",
    "    return easy_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reader = easyocr.Reader(['en'], gpu = True)\n",
    "reader_cpu = easyocr.Reader(['en'], gpu = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class WebGame(Env):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.observation_space = Box(low=0, high=255, shape = (1,84, 84), dtype=np.uint8)\n",
    "        self.action_space = Discrete(2)\n",
    "        self.cap = mss()\n",
    "        self.game_location = {'top':300, 'left':0, 'width':1400, \"height\":500}\n",
    "        self.done_location = {'top':385, 'left':630, 'width':680, \"height\":100}\n",
    "\n",
    "    def step(self, action):\n",
    "        action_map = {\n",
    "            0:'space',\n",
    "            1:'no_op'      \n",
    "        }\n",
    "        if action!=1: \n",
    "            pydirectinput.FAILSAFE = False\n",
    "            pydirectinput.press(action_map[action])\n",
    "        done = self.get_done()\n",
    "        observation  = self.get_observation()\n",
    "        reward = 1\n",
    "        info = {}\n",
    "        if action!=1:\n",
    "            time.sleep(0.2) \n",
    "\n",
    "        return observation, reward, done, info \n",
    "\n",
    "    def reset(self):\n",
    "        time.sleep(1)\n",
    "        pydirectinput.click(x=150, y=150)\n",
    "        pydirectinput.press('space')\n",
    "        return self.get_observation()\n",
    "\n",
    "\n",
    "    def get_observation(self):\n",
    "        raw = np.array(self.cap.grab(self.game_location))[:,:,:3]\n",
    "        gray = cv.cvtColor(raw, cv.COLOR_BGR2GRAY)\n",
    "        resized = cv.resize(gray, (84, 84))\n",
    "        channel = np.reshape(resized, (1, 84, 84))\n",
    "        \n",
    "        return channel\n",
    "\n",
    "    def get_done(self):\n",
    "        done_i = np.array(self.cap.grab(self.done_location))[:,:,:3]\n",
    "\n",
    "\n",
    "        done_strings = ['G A M E', 'G A H E', '6 A M E', '6AME', '6 A M E']\n",
    "\n",
    "        done = False\n",
    "        Image.fromarray(done_i).save('001.png')\n",
    "        res = easyocr_read('001.png', reader)[:7]\n",
    "        if res in done_strings:\n",
    "            done = True\n",
    "\n",
    "        return done"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import nn\n",
    "import torch.nn.functional as F\n",
    "import torch as T\n",
    "from collections import deque\n",
    "import itertools\n",
    "import random\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "T.cuda.is_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = 'cuda' if T.cuda.is_available() else 'cpu'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "GAMMA=0.99\n",
    "BATCH_SIZE=64\n",
    "BUFFER_SIZE=50000\n",
    "MIN_REPLAY_SIZE=1000\n",
    "EPSILON_START=1.0\n",
    "EPSILON_END=0.02\n",
    "EPSILON_DECAY=10000\n",
    "TARGET_UPDATE_FREQ = 1000\n",
    "lr = 3e-4\n",
    "episode_reward = 0.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def nature_cnn(obs, depths=(32, 64, 64), final_layer = 512):\n",
    "    n_input_channels = obs.shape[0]\n",
    "    cnn = nn.Sequential(\n",
    "        nn.Conv2d(n_input_channels, depths[0], kernel_size=8, stride=4),\n",
    "        nn.ReLU(),\n",
    "        nn.Conv2d(depths[0], depths[1], kernel_size=4, stride=2),\n",
    "        nn.ReLU(),\n",
    "        nn.Conv2d(depths[1], depths[2], kernel_size=2, stride=1),\n",
    "        nn.ReLU(),\n",
    "        nn.Flatten()\n",
    "    )\n",
    "    with T.no_grad():\n",
    "        n_flatten = cnn(T.as_tensor(obs.sample()[None]).float()).shape[1]\n",
    "    out = nn.Sequential(cnn, nn.Linear(n_flatten, final_layer), nn.ReLU())\n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Network(nn.Module):\n",
    "    def __init__(self, env):\n",
    "        super().__init__()\n",
    "\n",
    "        self.net = nn.Sequential(\n",
    "            nature_cnn(env.observation_space),\n",
    "            nn.Linear(512, env.action_space.n)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.net(x)\n",
    "\n",
    "    def act(self, obs):\n",
    "        obs_t = T.as_tensor(obs, dtype=T.float32).to(device)\n",
    "        q_values = self(obs_t.unsqueeze(0))\n",
    "        max_q_index = T.argmax(q_values, dim=1)[0]\n",
    "        action = max_q_index.detach().item()\n",
    "\n",
    "        return action\n",
    "\n",
    "    def train_loss(self, transitions, target_net):\n",
    "        obses = np.asarray([t[0] for t in transitions])\n",
    "        actions = np.asarray([t[1] for t in transitions])\n",
    "        rews = np.asarray([t[2] for t in transitions])\n",
    "        dones = np.asarray([t[3] for t in transitions])\n",
    "        new_obses = np.asarray([t[4] for t in transitions])\n",
    "\n",
    "        obses_t = T.as_tensor(obses, dtype=T.float32).to(device)\n",
    "        actions_t = T.as_tensor(actions, dtype=T.int64).unsqueeze(-1).to(device)\n",
    "        rews_t = T.as_tensor(rews, dtype=T.float32).unsqueeze(-1).to(device)\n",
    "        dones_t = T.as_tensor(dones, dtype=T.float32).unsqueeze(-1).to(device)\n",
    "        new_obses_t = T.as_tensor(new_obses, dtype=T.float32).to(device)\n",
    "\n",
    "        target_q_values = target_net(new_obses_t)\n",
    "        max_target_q_values = target_q_values.max(dim=1, keepdim=True)[0]\n",
    "\n",
    "        targets = rews_t + GAMMA*(1-dones_t)*max_target_q_values\n",
    "\n",
    "        q_values = self(obses_t)\n",
    "        action_q_values = T.gather(q_values, dim=1, index=actions_t)\n",
    "\n",
    "        loss = F.smooth_l1_loss(action_q_values, targets)\n",
    "        return loss\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "env = WebGame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "online_net = T.load('best_model/online.pth')\n",
    "target_net = T.load('best_model/target.pth')\n",
    "optimizer = T.load('best_model/optim.pth')  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# replay_buffer = deque(maxlen=BUFFER_SIZE)\n",
    "rew_buffer = deque([0.0], maxlen=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "replay_buffer = pickle.load(open('replay_buffer', 'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "import chromedriver_binary\n",
    "import time\n",
    "\n",
    "driver = webdriver.Chrome(executable_path='./chromedriver.exe')\n",
    "driver.maximize_window()\n",
    "try: \n",
    "    driver.get('chrome://dino')\n",
    "except:   \n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "obs = env.reset()\n",
    "time.sleep(2)\n",
    "for i in range(MIN_REPLAY_SIZE):\n",
    "    action = env.action_space.sample() \n",
    "    new_obs, rew, done, _ = env.step(action)\n",
    "    transition = (obs, action, rew, done, new_obs)\n",
    "    replay_buffer.append(transition)\n",
    "    obs = new_obs\n",
    "\n",
    "    if done:\n",
    "        obs = env.reset()\n",
    "\n",
    "obs = env.reset()\n",
    "time.sleep(2)\n",
    "for step in itertools.count():\n",
    "    epsilon = np.interp(step, [0, EPSILON_DECAY], [EPSILON_START, EPSILON_END])\n",
    "\n",
    "    rand = random.random()\n",
    "\n",
    "    if rand <= epsilon:\n",
    "        action = env.action_space.sample()\n",
    "    else:\n",
    "        action = online_net.act(obs)\n",
    "\n",
    "    new_obs, rew, done, _ = env.step(action)\n",
    "    transition = (obs, action, rew, done, new_obs)\n",
    "    replay_buffer.append(transition)\n",
    "    obs = new_obs\n",
    "\n",
    "    episode_reward += rew\n",
    "\n",
    "    if done:\n",
    "        obs = env.reset()\n",
    "        rew_buffer.append(episode_reward)\n",
    "        episode_reward = 0.0\n",
    "\n",
    "\n",
    "    transitions = random.sample(replay_buffer, BATCH_SIZE)\n",
    "\n",
    "    loss = online_net.train_loss(transitions, target_net)\n",
    "\n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "    if step%TARGET_UPDATE_FREQ == 0:\n",
    "        target_net.load_state_dict(online_net.state_dict())\n",
    "\n",
    "    if step%100 == 0:\n",
    "        print()\n",
    "        print('STEP', step)\n",
    "        print('Loss', loss)\n",
    "        print('Avg Reward', np.mean(rew_buffer))\n",
    "\n",
    "    if step%1000 == 0:\n",
    "        T.save(online_net, 'best_model/online.pth')\n",
    "        T.save(target_net, 'best_model/target.pth')\n",
    "        T.save(optimizer, 'best_model/optim.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "T.save(online_net, 'best_model/online.pth')\n",
    "T.save(target_net, 'best_model/target.pth')\n",
    "T.save(optimizer, 'best_model/optim.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle.dump(replay_buffer, open('replay_buffer', 'wb'))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.6 ('dino')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "40e8b55b721ca330211b0c6737fff585ca70e067ef3a4d4b73d73a980413d844"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
